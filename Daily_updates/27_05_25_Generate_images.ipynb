{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8827fad6-d494-4f48-bcf1-1233ad7f6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generating 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd543a2d-2568-4f67-90da-f2758497993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "GPU Name: NVIDIA RTX A5000\n",
      "GPU Memory Allocated: 0.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_28028\\3676617053.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cvae.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CVAE model from cvae_vehicle_final.pth\n",
      "Found 4793 images across 5 classes.\n",
      "Classes: ['Hatchback', 'Other', 'Pickup', 'Seden', 'SUV']\n",
      "Generating samples for class 0 (Hatchback)...\n",
      "Generated 1000 samples for class 0\n",
      "Generating samples for class 1 (Other)...\n",
      "Generated 1000 samples for class 1\n",
      "Generating samples for class 2 (Pickup)...\n",
      "Generated 1000 samples for class 2\n",
      "Generating samples for class 3 (Seden)...\n",
      "Generated 1000 samples for class 3\n",
      "Generating samples for class 4 (SUV)...\n",
      "Generated 1000 samples for class 4\n",
      "\n",
      "Class 0 (Hatchback) Metrics Statistics (1000 samples):\n",
      "PSNR - Mean: 8.43, Median: 8.48, Mode: 8.60\n",
      "SSIM - Mean: 0.0585, Median: 0.0537, Mode: 0.0460\n",
      "JS   - Mean: 0.3738, Median: 0.3724, Mode: 0.3620\n",
      "\n",
      "Class 1 (Other) Metrics Statistics (1000 samples):\n",
      "PSNR - Mean: 9.80, Median: 9.85, Mode: 10.10\n",
      "SSIM - Mean: 0.0756, Median: 0.0772, Mode: 0.0750\n",
      "JS   - Mean: 0.3327, Median: 0.3327, Mode: 0.3340\n",
      "\n",
      "Class 2 (Pickup) Metrics Statistics (1000 samples):\n",
      "PSNR - Mean: 8.36, Median: 8.35, Mode: 8.60\n",
      "SSIM - Mean: 0.0418, Median: 0.0374, Mode: 0.0370\n",
      "JS   - Mean: 0.3719, Median: 0.3703, Mode: 0.3570\n",
      "\n",
      "Class 3 (Seden) Metrics Statistics (1000 samples):\n",
      "PSNR - Mean: 8.79, Median: 8.45, Mode: 7.80\n",
      "SSIM - Mean: 0.0788, Median: 0.0665, Mode: 0.0610\n",
      "JS   - Mean: 0.3348, Median: 0.3403, Mode: 0.3560\n",
      "\n",
      "Class 4 (SUV) Metrics Statistics (1000 samples):\n",
      "PSNR - Mean: 7.62, Median: 7.66, Mode: 7.70\n",
      "SSIM - Mean: 0.0376, Median: 0.0346, Mode: 0.0270\n",
      "JS   - Mean: 0.4105, Median: 0.4118, Mode: 0.4040\n",
      "Finished generating 1000 enhanced samples per class and computing metrics\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy import stats\n",
    "import kagglehub\n",
    "\n",
    "# Hyperparameters\n",
    "RESIZE = 128\n",
    "intermediate_dim = 512\n",
    "latent_dim = 256\n",
    "num_classes = 5\n",
    "device = torch.device('cuda:1' if torch.cuda.device_count() > 1 else 'cuda')\n",
    "\n",
    "# Print GPU information\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Custom Dataset for Kaggle Vehicle Type Image Dataset (for reference images)\n",
    "class VehicleTypeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = []\n",
    "        self.class_to_idx = {}\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            image_files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "            if image_files:\n",
    "                class_name = os.path.basename(root)\n",
    "                if class_name not in self.class_to_idx:\n",
    "                    self.classes.append(class_name)\n",
    "                    self.class_to_idx[class_name] = len(self.classes) - 1\n",
    "                for img_file in image_files:\n",
    "                    img_path = os.path.join(root, img_file)\n",
    "                    try:\n",
    "                        Image.open(img_path).verify()\n",
    "                        self.images.append(img_path)\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "                    except:\n",
    "                        print(f\"Skipping corrupted image: {img_path}\")\n",
    "\n",
    "        if len(self.classes) != num_classes:\n",
    "            raise ValueError(f\"Expected {num_classes} classes, found {len(self.classes)}\")\n",
    "        print(f\"Found {len(self.images)} images across {len(self.classes)} classes.\")\n",
    "        print(f\"Classes: {self.classes}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "        return sample\n",
    "\n",
    "# Enhanced Image Grid for Plotting\n",
    "def image_grid(imgs, rows, cols, class_label, height=RESIZE, width=RESIZE):\n",
    "    assert len(imgs) <= rows * cols\n",
    "    grid = Image.new('RGB', size=(cols * width, rows * height), color=(255, 255, 255))\n",
    "    for i, img in enumerate(imgs):\n",
    "        x = (i % cols) * width + 2\n",
    "        y = (i // cols) * height + 2\n",
    "        grid.paste(img, box=(x, y))\n",
    "    return grid\n",
    "\n",
    "# Weight initialization function\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, latent_dim, num_classes):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_hidden = nn.Linear(1024 * 2 * 2 + num_classes, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_with_y = torch.cat([x, y], dim=-1)\n",
    "        h = F.relu(self.fc_hidden(x_with_y))\n",
    "        h = self.dropout(h)\n",
    "        z_mean = self.fc_mean(h)\n",
    "        z_logvar = self.fc_logvar(h)\n",
    "        z_logvar = torch.clamp(z_logvar, min=-10, max=10)\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "# Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_size, num_classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim + num_classes, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc_to_cnn = nn.Linear(hidden_dim, 1024 * 2 * 2)\n",
    "        self.decoder_cnn = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 1024, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 512, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        z_with_y = torch.cat([z, y], dim=-1)\n",
    "        h = F.relu(self.fc(z_with_y))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.fc_to_cnn(h))\n",
    "        h = h.view(-1, 1024, 2, 2)\n",
    "        x_reconstructed = self.decoder_cnn(h)\n",
    "        x_reconstructed = torch.clamp(x_reconstructed, min=-1, max=1)\n",
    "        return x_reconstructed\n",
    "\n",
    "# Conditional VAE class\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def reparameterize(self, z_mean, z_logvar):\n",
    "        std = torch.exp(0.5 * z_logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return z_mean + eps * std\n",
    "\n",
    "    def forward(self, data, y):\n",
    "        z_mean, z_logvar = self.encoder(data, y)\n",
    "        z = self.reparameterize(z_mean, z_logvar)\n",
    "        x_reconstructed = self.decoder(z, y)\n",
    "        return x_reconstructed, z_mean, z_logvar\n",
    "\n",
    "# Function to enhance image quality\n",
    "def enhance_image(pil_image):\n",
    "    pil_image = pil_image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))\n",
    "    pil_image = ImageEnhance.Sharpness(pil_image).enhance(2.0)\n",
    "    pil_image = ImageEnhance.Contrast(pil_image).enhance(1.3)\n",
    "    pil_image = ImageEnhance.Brightness(pil_image).enhance(1.1)\n",
    "    pil_image = pil_image.resize((RESIZE * 2, RESIZE * 2), Image.Resampling.LANCZOS)\n",
    "    pil_image = pil_image.resize((RESIZE, RESIZE), Image.Resampling.LANCZOS)\n",
    "    return pil_image\n",
    "\n",
    "# Function to compute PSNR, SSIM, and JS divergence\n",
    "def compute_metrics_for_image(orig, gen):\n",
    "    orig_np = orig.cpu().numpy() * 0.5 + 0.5\n",
    "    gen_np = gen.cpu().numpy() * 0.5 + 0.5\n",
    "    orig_np = np.transpose(orig_np, (1, 2, 0))\n",
    "    gen_np = np.transpose(gen_np, (1, 2, 0))\n",
    "    orig_np = np.clip(orig_np, 0, 1)\n",
    "    gen_np = np.clip(gen_np, 0, 1)\n",
    "\n",
    "    psnr_score = psnr(orig_np, gen_np, data_range=1.0)\n",
    "    ssim_score = ssim(orig_np, gen_np, multichannel=True, data_range=1.0, channel_axis=2)\n",
    "\n",
    "    js_scores = []\n",
    "    for c in range(3):\n",
    "        orig_channel = orig_np[:, :, c].flatten()\n",
    "        gen_channel = gen_np[:, :, c].flatten()\n",
    "        orig_channel = (orig_channel + 1e-10) / (np.sum(orig_channel) + 1e-10 * RESIZE * RESIZE)\n",
    "        gen_channel = (gen_channel + 1e-10) / (np.sum(gen_channel) + 1e-10 * RESIZE * RESIZE)\n",
    "        js_score = jensenshannon(orig_channel, gen_channel)\n",
    "        if np.isnan(js_score):\n",
    "            js_score = 1.0\n",
    "        js_scores.append(js_score)\n",
    "    js_score = np.mean(js_scores)\n",
    "\n",
    "    return psnr_score, ssim_score, js_score\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = (8, 3, RESIZE, RESIZE)\n",
    "encoder = Encoder(input_size, intermediate_dim, latent_dim, num_classes).to(device)\n",
    "decoder = Decoder(latent_dim, intermediate_dim, input_size, num_classes).to(device)\n",
    "cvae = ConditionalVAE(encoder, decoder).to(device)\n",
    "\n",
    "# Load the saved model weights\n",
    "model_path = \"cvae_vehicle_final.pth\"\n",
    "try:\n",
    "    cvae.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(f\"Loaded CVAE model from {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Load reference images for metrics computation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((RESIZE, RESIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "path = kagglehub.dataset_download(\"sujaykapadnis/vehicle-type-image-dataset\")\n",
    "dataset = VehicleTypeDataset(root_dir=path, transform=transform)\n",
    "\n",
    "# Collect reference images (5 per class)\n",
    "reference_images = {i: [] for i in range(num_classes)}\n",
    "for sample in dataset:\n",
    "    label = sample['label']\n",
    "    if len(reference_images[label]) < 5:\n",
    "        reference_images[label].append(sample['image'])\n",
    "    if all(len(refs) >= 5 for refs in reference_images.values()):\n",
    "        break\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Hatchback', 'Other', 'Pickup', 'Seden', 'SUV']\n",
    "\n",
    "# Modified generate_samples_labelwise function to generate 1000 samples and compute statistics\n",
    "def generate_samples_labelwise(cvae, num_samples_per_class, base_dir, latent_dim, device):\n",
    "    cvae.eval()\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize dictionary to store metrics\n",
    "    all_metrics = {class_label: [] for class_label in range(num_classes)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for class_label in range(num_classes):\n",
    "            print(f\"Generating samples for class {class_label} ({class_names[class_label]})...\")\n",
    "            label_tensor = torch.tensor([class_label]).repeat(num_samples_per_class).to(device)\n",
    "            one_hot_labels = F.one_hot(label_tensor, num_classes=num_classes).float().to(device)\n",
    "\n",
    "            # Generate samples in smaller batches to avoid memory issues\n",
    "            batch_size = 50\n",
    "            idx = 0\n",
    "            for start_idx in range(0, num_samples_per_class, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, num_samples_per_class)\n",
    "                current_batch_size = end_idx - start_idx\n",
    "\n",
    "                # Use truncation trick\n",
    "                z = torch.randn(current_batch_size, latent_dim).to(device) * 0.7\n",
    "                z = torch.clamp(z, -2.0, 2.0)\n",
    "                generated_samples = cvae.decoder(z, one_hot_labels[start_idx:end_idx])\n",
    "\n",
    "                # Process and save each sample\n",
    "                class_dir = os.path.join(base_dir, str(class_label))\n",
    "                os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "                images_for_grid = []\n",
    "                for batch_idx, sample in enumerate(generated_samples):\n",
    "                    global_idx = start_idx + batch_idx\n",
    "                    # Convert tensor to numpy array\n",
    "                    sample = sample.cpu().detach().numpy()\n",
    "                    sample = sample * 0.5 + 0.5\n",
    "                    sample = np.nan_to_num(sample, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    sample = (255 * sample).astype(np.uint8)\n",
    "                    sample = np.transpose(sample, (1, 2, 0))\n",
    "                    pil_image = Image.fromarray(sample).convert('RGB')\n",
    "\n",
    "                    # Enhance the image\n",
    "                    pil_image = enhance_image(pil_image)\n",
    "\n",
    "                    # Save the enhanced image\n",
    "                    pil_image.save(os.path.join(class_dir, f\"sample_{global_idx}.png\"))\n",
    "                    if global_idx < 32:\n",
    "                        images_for_grid.append(pil_image)\n",
    "\n",
    "                    # Convert back to tensor for metrics computation\n",
    "                    gen_tensor = transform(pil_image).to(device)\n",
    "\n",
    "                    # Compute metrics against reference images\n",
    "                    ref_images = reference_images[class_label]\n",
    "                    psnr_scores, ssim_scores, js_scores = [], [], []\n",
    "                    for ref_tensor in ref_images:\n",
    "                        psnr_score, ssim_score, js_score = compute_metrics_for_image(ref_tensor, gen_tensor)\n",
    "                        psnr_scores.append(psnr_score)\n",
    "                        ssim_scores.append(ssim_score)\n",
    "                        js_scores.append(js_score)\n",
    "\n",
    "                    avg_psnr = np.mean(psnr_scores)\n",
    "                    avg_ssim = np.mean(ssim_scores)\n",
    "                    avg_js = np.mean(js_scores)\n",
    "\n",
    "                    all_metrics[class_label].append({\n",
    "                        'image': f\"sample_{global_idx}.png\",\n",
    "                        'psnr': avg_psnr,\n",
    "                        'ssim': avg_ssim,\n",
    "                        'js': avg_js\n",
    "                    })\n",
    "\n",
    "                idx += current_batch_size\n",
    "\n",
    "            # Save a grid of the first 32 images\n",
    "            if images_for_grid:\n",
    "                grid = image_grid(images_for_grid, rows=4, cols=8, class_label=class_names[class_label])\n",
    "                grid.save(os.path.join(class_dir, f\"grid_{class_names[class_label]}.png\"))\n",
    "            print(f\"Generated {num_samples_per_class} samples for class {class_label}\")\n",
    "\n",
    "    # Compute and print mean, median, mode for each class\n",
    "    for class_label in range(num_classes):\n",
    "        psnr_values = np.array([metric['psnr'] for metric in all_metrics[class_label]])\n",
    "        ssim_values = np.array([metric['ssim'] for metric in all_metrics[class_label]])\n",
    "        js_values = np.array([metric['js'] for metric in all_metrics[class_label]])\n",
    "\n",
    "        # Compute mean\n",
    "        psnr_mean = np.mean(psnr_values)\n",
    "        ssim_mean = np.mean(ssim_values)\n",
    "        js_mean = np.mean(js_values)\n",
    "\n",
    "        # Compute median\n",
    "        psnr_median = np.median(psnr_values)\n",
    "        ssim_median = np.median(ssim_values)\n",
    "        js_median = np.median(js_values)\n",
    "\n",
    "        # Compute mode (approximate by binning for continuous data)\n",
    "        psnr_mode = stats.mode(np.round(psnr_values, 1), keepdims=False)[0]\n",
    "        ssim_mode = stats.mode(np.round(ssim_values, 3), keepdims=False)[0]\n",
    "        js_mode = stats.mode(np.round(js_values, 3), keepdims=False)[0]\n",
    "\n",
    "        print(f\"\\nClass {class_label} ({class_names[class_label]}) Metrics Statistics (1000 samples):\")\n",
    "        print(f\"PSNR - Mean: {psnr_mean:.2f}, Median: {psnr_median:.2f}, Mode: {psnr_mode:.2f}\")\n",
    "        print(f\"SSIM - Mean: {ssim_mean:.4f}, Median: {ssim_median:.4f}, Mode: {ssim_mode:.4f}\")\n",
    "        print(f\"JS   - Mean: {js_mean:.4f}, Median: {js_median:.4f}, Mode: {js_mode:.4f}\")\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "# Generate 1000 samples per class and compute metrics\n",
    "base_dir = \"generated_samples-arch-A5-1000-enhanced\"\n",
    "try:\n",
    "    all_metrics = generate_samples_labelwise(\n",
    "        cvae, num_samples_per_class=1000, base_dir=base_dir, \n",
    "        latent_dim=latent_dim, device=device\n",
    "    )\n",
    "    print(\"Finished generating 1000 enhanced samples per class and computing metrics\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during sample generation: {str(e)}\")\n",
    "\n",
    "# Clear GPU memory\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a61024-a6ca-4ffd-aecc-1bf8cb713d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 (Hatchback) Metrics Statistics (1000 samples):\n",
      "PSNR - Max: 10.50, Min: 5.85, Mean: 8.43, Median: 8.48, Mode: 8.60\n",
      "SSIM - Max: 0.1431, Min: 0.0125, Mean: 0.0585, Median: 0.0537, Mode: 0.0460\n",
      "JS   - Max: 0.4676, Min: 0.2906, Mean: 0.3738, Median: 0.3724, Mode: 0.3620\n",
      "\n",
      "Class 1 (Other) Metrics Statistics (1000 samples):\n",
      "PSNR - Max: 11.23, Min: 6.93, Mean: 9.80, Median: 9.85, Mode: 10.10\n",
      "SSIM - Max: 0.1404, Min: 0.0175, Mean: 0.0756, Median: 0.0772, Mode: 0.0750\n",
      "JS   - Max: 0.4303, Min: 0.2495, Mean: 0.3327, Median: 0.3327, Mode: 0.3340\n",
      "\n",
      "Class 2 (Pickup) Metrics Statistics (1000 samples):\n",
      "PSNR - Max: 10.37, Min: 6.22, Mean: 8.36, Median: 8.35, Mode: 8.60\n",
      "SSIM - Max: 0.1554, Min: 0.0027, Mean: 0.0418, Median: 0.0374, Mode: 0.0370\n",
      "JS   - Max: 0.4608, Min: 0.2907, Mean: 0.3719, Median: 0.3703, Mode: 0.3570\n",
      "\n",
      "Class 3 (Seden) Metrics Statistics (1000 samples):\n",
      "PSNR - Max: 11.30, Min: 6.51, Mean: 8.79, Median: 8.45, Mode: 7.80\n",
      "SSIM - Max: 0.1789, Min: 0.0117, Mean: 0.0788, Median: 0.0665, Mode: 0.0610\n",
      "JS   - Max: 0.4558, Min: 0.2478, Mean: 0.3348, Median: 0.3403, Mode: 0.3560\n",
      "\n",
      "Class 4 (SUV) Metrics Statistics (1000 samples):\n",
      "PSNR - Max: 9.27, Min: 6.03, Mean: 7.62, Median: 7.66, Mode: 7.70\n",
      "SSIM - Max: 0.1482, Min: 0.0039, Mean: 0.0376, Median: 0.0346, Mode: 0.0270\n",
      "JS   - Max: 0.4700, Min: 0.3012, Mean: 0.4105, Median: 0.4118, Mode: 0.4040\n"
     ]
    }
   ],
   "source": [
    "    # Compute and print max, min, mean, median, mode for each class\n",
    "    for class_label in range(num_classes):\n",
    "        psnr_values = np.array([metric['psnr'] for metric in all_metrics[class_label]])\n",
    "        ssim_values = np.array([metric['ssim'] for metric in all_metrics[class_label]])\n",
    "        js_values = np.array([metric['js'] for metric in all_metrics[class_label]])\n",
    "\n",
    "        # Compute max and min\n",
    "        psnr_max = np.max(psnr_values)\n",
    "        psnr_min = np.min(psnr_values)\n",
    "        ssim_max = np.max(ssim_values)\n",
    "        ssim_min = np.min(ssim_values)\n",
    "        js_max = np.max(js_values)\n",
    "        js_min = np.min(js_values)\n",
    "\n",
    "        # Compute mean\n",
    "        psnr_mean = np.mean(psnr_values)\n",
    "        ssim_mean = np.mean(ssim_values)\n",
    "        js_mean = np.mean(js_values)\n",
    "\n",
    "        # Compute median\n",
    "        psnr_median = np.median(psnr_values)\n",
    "        ssim_median = np.median(ssim_values)\n",
    "        js_median = np.median(js_values)\n",
    "\n",
    "        # Compute mode (approximate by binning for continuous data)\n",
    "        psnr_mode = stats.mode(np.round(psnr_values, 1), keepdims=False)[0]\n",
    "        ssim_mode = stats.mode(np.round(ssim_values, 3), keepdims=False)[0]\n",
    "        js_mode = stats.mode(np.round(js_values, 3), keepdims=False)[0]\n",
    "\n",
    "        print(f\"\\nClass {class_label} ({class_names[class_label]}) Metrics Statistics (1000 samples):\")\n",
    "        print(f\"PSNR - Max: {psnr_max:.2f}, Min: {psnr_min:.2f}, Mean: {psnr_mean:.2f}, Median: {psnr_median:.2f}, Mode: {psnr_mode:.2f}\")\n",
    "        print(f\"SSIM - Max: {ssim_max:.4f}, Min: {ssim_min:.4f}, Mean: {ssim_mean:.4f}, Median: {ssim_median:.4f}, Mode: {ssim_mode:.4f}\")\n",
    "        print(f\"JS   - Max: {js_max:.4f}, Min: {js_min:.4f}, Mean: {js_mean:.4f}, Median: {js_median:.4f}, Mode: {js_mode:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a064e32-c08f-4ce7-b164-768c28f706ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##selecting_good_images_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f07530-81f8-4ecb-9d48-e17456b52f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 (Hatchback): Only 254 images met the criteria. Selecting top 500 by combined score.\n",
      "Class 0 (Hatchback): Selected 500 top images saved to top_500_images_per_class\\0\n",
      "\n",
      "Class 0 (Hatchback) Top 10 Images:\n",
      "Image: sample_975.png, PSNR: 9.77, SSIM: 0.1405, JS: 0.3013, Score: 8.17\n",
      "Image: sample_230.png, PSNR: 10.34, SSIM: 0.1093, JS: 0.3274, Score: 8.15\n",
      "Image: sample_50.png, PSNR: 10.50, SSIM: 0.1198, JS: 0.3556, Score: 8.14\n",
      "Image: sample_401.png, PSNR: 10.36, SSIM: 0.1121, JS: 0.3361, Score: 8.12\n",
      "Image: sample_431.png, PSNR: 10.35, SSIM: 0.1174, JS: 0.3474, Score: 8.05\n",
      "Image: sample_624.png, PSNR: 9.57, SSIM: 0.1431, JS: 0.3099, Score: 7.90\n",
      "Image: sample_619.png, PSNR: 9.95, SSIM: 0.1121, JS: 0.3266, Score: 7.81\n",
      "Image: sample_547.png, PSNR: 9.53, SSIM: 0.1315, JS: 0.3138, Score: 7.71\n",
      "Image: sample_327.png, PSNR: 10.20, SSIM: 0.0925, JS: 0.3410, Score: 7.71\n",
      "Image: sample_28.png, PSNR: 10.01, SSIM: 0.1068, JS: 0.3393, Score: 7.69\n",
      "\n",
      "Class 0 (Hatchback) Bottom 10 Images:\n",
      "Image: sample_992.png, PSNR: 5.90, SSIM: 0.0257, JS: 0.3350, Score: 2.81\n",
      "Image: sample_609.png, PSNR: 6.14, SSIM: 0.0162, JS: 0.3525, Score: 2.78\n",
      "Image: sample_216.png, PSNR: 6.50, SSIM: 0.0246, JS: 0.4009, Score: 2.74\n",
      "Image: sample_753.png, PSNR: 6.51, SSIM: 0.0160, JS: 0.3983, Score: 2.69\n",
      "Image: sample_108.png, PSNR: 6.11, SSIM: 0.0170, JS: 0.3652, Score: 2.63\n",
      "Image: sample_441.png, PSNR: 5.90, SSIM: 0.0230, JS: 0.3592, Score: 2.54\n",
      "Image: sample_238.png, PSNR: 5.98, SSIM: 0.0181, JS: 0.3627, Score: 2.53\n",
      "Image: sample_221.png, PSNR: 5.85, SSIM: 0.0153, JS: 0.3618, Score: 2.39\n",
      "Image: sample_542.png, PSNR: 5.94, SSIM: 0.0190, JS: 0.3777, Score: 2.35\n",
      "Image: sample_302.png, PSNR: 6.41, SSIM: 0.0193, JS: 0.4246, Score: 2.35\n",
      "Class 1 (Other): Only 244 images met the criteria. Selecting top 500 by combined score.\n",
      "Class 1 (Other): Selected 500 top images saved to top_500_images_per_class\\1\n",
      "\n",
      "Class 1 (Other) Top 10 Images:\n",
      "Image: sample_672.png, PSNR: 11.23, SSIM: 0.1390, JS: 0.2495, Score: 10.13\n",
      "Image: sample_403.png, PSNR: 11.18, SSIM: 0.1031, JS: 0.2511, Score: 9.71\n",
      "Image: sample_897.png, PSNR: 11.23, SSIM: 0.1115, JS: 0.2670, Score: 9.67\n",
      "Image: sample_820.png, PSNR: 11.13, SSIM: 0.0976, JS: 0.2612, Score: 9.49\n",
      "Image: sample_613.png, PSNR: 10.97, SSIM: 0.1212, JS: 0.2723, Score: 9.46\n",
      "Image: sample_585.png, PSNR: 10.92, SSIM: 0.1115, JS: 0.2665, Score: 9.37\n",
      "Image: sample_431.png, PSNR: 10.98, SSIM: 0.0993, JS: 0.2610, Score: 9.36\n",
      "Image: sample_343.png, PSNR: 10.95, SSIM: 0.1113, JS: 0.2742, Score: 9.32\n",
      "Image: sample_185.png, PSNR: 10.89, SSIM: 0.1051, JS: 0.2654, Score: 9.29\n",
      "Image: sample_953.png, PSNR: 10.98, SSIM: 0.1055, JS: 0.2810, Score: 9.23\n",
      "\n",
      "Class 1 (Other) Bottom 10 Images:\n",
      "Image: sample_874.png, PSNR: 8.26, SSIM: 0.0222, JS: 0.3618, Score: 4.86\n",
      "Image: sample_152.png, PSNR: 7.91, SSIM: 0.0377, JS: 0.3459, Score: 4.83\n",
      "Image: sample_861.png, PSNR: 8.41, SSIM: 0.0336, JS: 0.3935, Score: 4.81\n",
      "Image: sample_698.png, PSNR: 8.41, SSIM: 0.0252, JS: 0.3874, Score: 4.79\n",
      "Image: sample_221.png, PSNR: 7.71, SSIM: 0.0246, JS: 0.3228, Score: 4.72\n",
      "Image: sample_875.png, PSNR: 7.40, SSIM: 0.0423, JS: 0.3350, Score: 4.48\n",
      "Image: sample_301.png, PSNR: 7.72, SSIM: 0.0276, JS: 0.3533, Score: 4.47\n",
      "Image: sample_634.png, PSNR: 7.83, SSIM: 0.0175, JS: 0.3774, Score: 4.24\n",
      "Image: sample_999.png, PSNR: 7.28, SSIM: 0.0262, JS: 0.3713, Score: 3.83\n",
      "Image: sample_397.png, PSNR: 6.93, SSIM: 0.0365, JS: 0.3571, Score: 3.72\n",
      "Class 2 (Pickup): Only 203 images met the criteria. Selecting top 500 by combined score.\n",
      "Class 2 (Pickup): Selected 500 top images saved to top_500_images_per_class\\2\n",
      "\n",
      "Class 2 (Pickup) Top 10 Images:\n",
      "Image: sample_846.png, PSNR: 10.37, SSIM: 0.1554, JS: 0.3117, Score: 8.80\n",
      "Image: sample_323.png, PSNR: 10.37, SSIM: 0.1446, JS: 0.3079, Score: 8.73\n",
      "Image: sample_561.png, PSNR: 10.15, SSIM: 0.1295, JS: 0.3033, Score: 8.42\n",
      "Image: sample_537.png, PSNR: 10.11, SSIM: 0.1366, JS: 0.3210, Score: 8.27\n",
      "Image: sample_955.png, PSNR: 10.12, SSIM: 0.1059, JS: 0.3036, Score: 8.14\n",
      "Image: sample_439.png, PSNR: 10.04, SSIM: 0.1295, JS: 0.3315, Score: 8.02\n",
      "Image: sample_878.png, PSNR: 9.95, SSIM: 0.1116, JS: 0.3067, Score: 8.00\n",
      "Image: sample_111.png, PSNR: 10.03, SSIM: 0.1138, JS: 0.3293, Score: 7.87\n",
      "Image: sample_597.png, PSNR: 9.74, SSIM: 0.1239, JS: 0.3167, Score: 7.81\n",
      "Image: sample_992.png, PSNR: 9.68, SSIM: 0.1225, JS: 0.3098, Score: 7.81\n",
      "\n",
      "Class 2 (Pickup) Bottom 10 Images:\n",
      "Image: sample_454.png, PSNR: 6.78, SSIM: 0.0118, JS: 0.3700, Score: 3.20\n",
      "Image: sample_606.png, PSNR: 6.27, SSIM: 0.0277, JS: 0.3375, Score: 3.17\n",
      "Image: sample_235.png, PSNR: 6.22, SSIM: 0.0290, JS: 0.3357, Score: 3.15\n",
      "Image: sample_442.png, PSNR: 6.38, SSIM: 0.0182, JS: 0.3410, Score: 3.15\n",
      "Image: sample_650.png, PSNR: 6.68, SSIM: 0.0241, JS: 0.3780, Score: 3.14\n",
      "Image: sample_646.png, PSNR: 6.89, SSIM: 0.0183, JS: 0.3978, Score: 3.09\n",
      "Image: sample_935.png, PSNR: 6.86, SSIM: 0.0116, JS: 0.3968, Score: 3.01\n",
      "Image: sample_100.png, PSNR: 6.63, SSIM: 0.0061, JS: 0.3689, Score: 3.00\n",
      "Image: sample_256.png, PSNR: 6.65, SSIM: 0.0027, JS: 0.3763, Score: 2.91\n",
      "Image: sample_387.png, PSNR: 6.47, SSIM: 0.0047, JS: 0.3710, Score: 2.81\n",
      "Class 3 (Seden): Only 336 images met the criteria. Selecting top 500 by combined score.\n",
      "Class 3 (Seden): Selected 500 top images saved to top_500_images_per_class\\3\n",
      "\n",
      "Class 3 (Seden) Top 10 Images:\n",
      "Image: sample_943.png, PSNR: 11.24, SSIM: 0.1789, JS: 0.2536, Score: 10.49\n",
      "Image: sample_237.png, PSNR: 11.24, SSIM: 0.1771, JS: 0.2594, Score: 10.41\n",
      "Image: sample_22.png, PSNR: 11.08, SSIM: 0.1763, JS: 0.2478, Score: 10.37\n",
      "Image: sample_433.png, PSNR: 11.00, SSIM: 0.1760, JS: 0.2550, Score: 10.21\n",
      "Image: sample_57.png, PSNR: 11.13, SSIM: 0.1620, JS: 0.2579, Score: 10.17\n",
      "Image: sample_482.png, PSNR: 11.02, SSIM: 0.1669, JS: 0.2536, Score: 10.15\n",
      "Image: sample_594.png, PSNR: 11.10, SSIM: 0.1600, JS: 0.2558, Score: 10.15\n",
      "Image: sample_120.png, PSNR: 11.30, SSIM: 0.1480, JS: 0.2646, Score: 10.13\n",
      "Image: sample_79.png, PSNR: 11.04, SSIM: 0.1573, JS: 0.2594, Score: 10.02\n",
      "Image: sample_248.png, PSNR: 11.15, SSIM: 0.1497, JS: 0.2639, Score: 10.01\n",
      "\n",
      "Class 3 (Seden) Bottom 10 Images:\n",
      "Image: sample_628.png, PSNR: 7.03, SSIM: 0.0375, JS: 0.4222, Score: 3.18\n",
      "Image: sample_708.png, PSNR: 7.07, SSIM: 0.0224, JS: 0.4125, Score: 3.17\n",
      "Image: sample_291.png, PSNR: 6.81, SSIM: 0.0117, JS: 0.3760, Score: 3.17\n",
      "Image: sample_407.png, PSNR: 6.76, SSIM: 0.0254, JS: 0.3844, Score: 3.17\n",
      "Image: sample_84.png, PSNR: 6.53, SSIM: 0.0296, JS: 0.3784, Score: 3.04\n",
      "Image: sample_858.png, PSNR: 6.85, SSIM: 0.0232, JS: 0.4051, Score: 3.03\n",
      "Image: sample_598.png, PSNR: 6.51, SSIM: 0.0241, JS: 0.3784, Score: 2.96\n",
      "Image: sample_123.png, PSNR: 6.96, SSIM: 0.0216, JS: 0.4219, Score: 2.95\n",
      "Image: sample_554.png, PSNR: 7.04, SSIM: 0.0237, JS: 0.4352, Score: 2.93\n",
      "Image: sample_918.png, PSNR: 6.86, SSIM: 0.0195, JS: 0.4188, Score: 2.87\n",
      "Class 4 (SUV): Only 203 images met the criteria. Selecting top 500 by combined score.\n",
      "Class 4 (SUV): Selected 500 top images saved to top_500_images_per_class\\4\n",
      "\n",
      "Class 4 (SUV) Top 10 Images:\n",
      "Image: sample_634.png, PSNR: 8.59, SSIM: 0.1482, JS: 0.3060, Score: 7.01\n",
      "Image: sample_856.png, PSNR: 8.89, SSIM: 0.1085, JS: 0.3158, Score: 6.82\n",
      "Image: sample_920.png, PSNR: 9.27, SSIM: 0.0988, JS: 0.3464, Score: 6.79\n",
      "Image: sample_23.png, PSNR: 8.37, SSIM: 0.1173, JS: 0.3015, Score: 6.53\n",
      "Image: sample_552.png, PSNR: 8.93, SSIM: 0.0795, JS: 0.3356, Score: 6.36\n",
      "Image: sample_115.png, PSNR: 9.15, SSIM: 0.0838, JS: 0.3656, Score: 6.33\n",
      "Image: sample_33.png, PSNR: 8.91, SSIM: 0.0488, JS: 0.3303, Score: 6.10\n",
      "Image: sample_82.png, PSNR: 8.37, SSIM: 0.0749, JS: 0.3046, Score: 6.07\n",
      "Image: sample_421.png, PSNR: 8.24, SSIM: 0.0848, JS: 0.3024, Score: 6.07\n",
      "Image: sample_732.png, PSNR: 8.20, SSIM: 0.0874, JS: 0.3015, Score: 6.06\n",
      "\n",
      "Class 4 (SUV) Bottom 10 Images:\n",
      "Image: sample_653.png, PSNR: 6.90, SSIM: 0.0189, JS: 0.4496, Score: 2.59\n",
      "Image: sample_32.png, PSNR: 6.54, SSIM: 0.0130, JS: 0.4104, Score: 2.57\n",
      "Image: sample_869.png, PSNR: 6.14, SSIM: 0.0166, JS: 0.3753, Score: 2.56\n",
      "Image: sample_481.png, PSNR: 6.84, SSIM: 0.0260, JS: 0.4542, Score: 2.56\n",
      "Image: sample_469.png, PSNR: 6.62, SSIM: 0.0210, JS: 0.4282, Score: 2.55\n",
      "Image: sample_631.png, PSNR: 6.74, SSIM: 0.0237, JS: 0.4521, Score: 2.45\n",
      "Image: sample_564.png, PSNR: 6.07, SSIM: 0.0145, JS: 0.3774, Score: 2.44\n",
      "Image: sample_104.png, PSNR: 6.07, SSIM: 0.0146, JS: 0.3776, Score: 2.44\n",
      "Image: sample_73.png, PSNR: 6.15, SSIM: 0.0137, JS: 0.4026, Score: 2.26\n",
      "Image: sample_106.png, PSNR: 6.03, SSIM: 0.0173, JS: 0.4053, Score: 2.15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming all_metrics is available from the previous code\n",
    "# If not, you'd need to recompute it by running the metrics computation part of the previous code\n",
    "# all_metrics is a dictionary: {class_label: [{'image': 'sample_X.png', 'psnr': ..., 'ssim': ..., 'js': ...}, ...]}\n",
    "\n",
    "# Define directories\n",
    "base_dir = \"generated_samples-arch-A5-1000-enhanced\"\n",
    "good_images_dir = \"top_500_images_per_class\"\n",
    "os.makedirs(good_images_dir, exist_ok=True)\n",
    "\n",
    "# Class names (for printing)\n",
    "class_names = ['Hatchback', 'Other', 'Pickup', 'Seden', 'SUV']\n",
    "\n",
    "# Define class-specific thresholds based on the provided statistics\n",
    "thresholds = {\n",
    "    0: {'psnr': 8.5, 'ssim': 0.06, 'js': 0.37},  # Hatchback\n",
    "    1: {'psnr': 9.9, 'ssim': 0.08, 'js': 0.33},  # Other\n",
    "    2: {'psnr': 8.4, 'ssim': 0.045, 'js': 0.37}, # Pickup\n",
    "    3: {'psnr': 8.8, 'ssim': 0.08, 'js': 0.33},  # Seden\n",
    "    4: {'psnr': 7.7, 'ssim': 0.04, 'js': 0.41}   # SUV\n",
    "}\n",
    "\n",
    "# Select top 500 images per class\n",
    "top_images = {class_label: [] for class_label in range(num_classes)}\n",
    "combined_scores = {class_label: [] for class_label in range(num_classes)}\n",
    "\n",
    "for class_label in range(num_classes):\n",
    "    class_dir = os.path.join(base_dir, str(class_label))\n",
    "    good_class_dir = os.path.join(good_images_dir, str(class_label))\n",
    "    os.makedirs(good_class_dir, exist_ok=True)\n",
    "\n",
    "    # Apply class-specific thresholds\n",
    "    good_candidates = []\n",
    "    for metric in all_metrics[class_label]:\n",
    "        avg_psnr = metric['psnr']\n",
    "        avg_ssim = metric['ssim']\n",
    "        avg_js = metric['js']\n",
    "        thresh = thresholds[class_label]\n",
    "\n",
    "        if avg_psnr > thresh['psnr'] and avg_ssim > thresh['ssim'] and avg_js < thresh['js']:\n",
    "            good_candidates.append({\n",
    "                'image': metric['image'],\n",
    "                'psnr': avg_psnr,\n",
    "                'ssim': avg_ssim,\n",
    "                'js': avg_js\n",
    "            })\n",
    "\n",
    "    # Compute combined score for sorting (PSNR + SSIM * 10 - JS * 10)\n",
    "    for metric in all_metrics[class_label]:\n",
    "        score = metric['psnr'] + metric['ssim'] * 10 - metric['js'] * 10\n",
    "        combined_scores[class_label].append({\n",
    "            'image': metric['image'],\n",
    "            'psnr': metric['psnr'],\n",
    "            'ssim': metric['ssim'],\n",
    "            'js': metric['js'],\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "    # Sort by combined score (descending)\n",
    "    combined_scores[class_label].sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    # If we have enough good candidates, select the top 500 by score\n",
    "    if len(good_candidates) >= 500:\n",
    "        good_candidates.sort(key=lambda x: (x['psnr'] + x['ssim'] * 10 - x['js'] * 10), reverse=True)\n",
    "        top_images[class_label] = good_candidates[:500]\n",
    "    else:\n",
    "        # If fewer than 500 meet the criteria, take the top 500 by combined score\n",
    "        top_images[class_label] = combined_scores[class_label][:500]\n",
    "        print(f\"Class {class_label} ({class_names[class_label]}): Only {len(good_candidates)} images met the criteria. Selecting top 500 by combined score.\")\n",
    "\n",
    "    # Save the top 500 images\n",
    "    for img_data in top_images[class_label]:\n",
    "        src_path = os.path.join(class_dir, img_data['image'])\n",
    "        dst_path = os.path.join(good_class_dir, img_data['image'])\n",
    "        pil_image = Image.open(src_path)\n",
    "        pil_image.save(dst_path)\n",
    "\n",
    "    # Print the number of selected images\n",
    "    print(f\"Class {class_label} ({class_names[class_label]}): Selected {len(top_images[class_label])} top images saved to {good_class_dir}\")\n",
    "\n",
    "    # Print top 10 and bottom 10 images based on combined score\n",
    "    print(f\"\\nClass {class_label} ({class_names[class_label]}) Top 10 Images:\")\n",
    "    for i in range(min(10, len(combined_scores[class_label]))):\n",
    "        img_data = combined_scores[class_label][i]\n",
    "        print(f\"Image: {img_data['image']}, PSNR: {img_data['psnr']:.2f}, SSIM: {img_data['ssim']:.4f}, JS: {img_data['js']:.4f}, Score: {img_data['score']:.2f}\")\n",
    "\n",
    "    print(f\"\\nClass {class_label} ({class_names[class_label]}) Bottom 10 Images:\")\n",
    "    for i in range(max(0, len(combined_scores[class_label]) - 10), len(combined_scores[class_label])):\n",
    "        img_data = combined_scores[class_label][i]\n",
    "        print(f\"Image: {img_data['image']}, PSNR: {img_data['psnr']:.2f}, SSIM: {img_data['ssim']:.4f}, JS: {img_data['js']:.4f}, Score: {img_data['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363595dc-25e5-45c4-b823-77f88ced2623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
